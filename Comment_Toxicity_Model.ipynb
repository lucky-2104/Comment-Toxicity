{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ade9203",
   "metadata": {},
   "source": [
    "# 0.Installing dependencies And Bring in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95ac163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3505b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.0.post10)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d3f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6379b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3899e605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jigsaw-toxic-comment-classification-challenge\\\\train.csv\\\\train.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv','train.csv')\n",
    "path # gives us the path of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3706215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "806532d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96fea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12]['comment_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18afef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2 :]].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c01aced",
   "metadata": {},
   "source": [
    "# 1.Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3006f1",
   "metadata": {},
   "source": [
    "### a.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba8a2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1911dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values #.values converts the df to array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8519ba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list1= X.values;\n",
    "for x in list1:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f36a469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e2c4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # number of word in the vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85ad7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens = MAX_FEATURES , \n",
    "                              output_sequence_length = 1800,\n",
    "                              output_mode ='int')\n",
    "#Max_tokens = How many word we want in our vocabulary\n",
    "# Maximum length of token = output_sequence_length\n",
    "#output mode = interger mapping everyword to integer like  I -> 64 and like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a646214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.preprocessing.text_vectorization.TextVectorization at 0x1bbc37aa310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5d8c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5ca52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21be56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aac67d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1799, 1800), dtype=int64, numpy=\n",
       "array([[ 645,   76,    2, ...,    0,    0,    0],\n",
       "       [   1,   54, 2489, ...,    0,    0,    0],\n",
       "       [ 425,  441,   70, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  49,  447,  752, ...,    0,    0,    0],\n",
       "       [  21,  582,    9, ...,    0,    0,    0],\n",
       "       [ 616,   19,    6, ...,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text[:1799]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a016c7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4850f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCSHBAP - map , cache ,shuffle , batch , prefetch \n",
    "#For Pipelining\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps prevent bottelnecks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d363d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1      2     3     4      5     6      7     8      9     ...  \\\n",
      "0   180877   992      9  7957   199  64168  2103   7439  2417      5  ...   \n",
      "1       21   467    425     7   118      3  7952     33     7     72  ...   \n",
      "2        2     1   1464   160  2673     10  1397  34294     9  46806  ...   \n",
      "3      863  1646  28701     4  6712      8    25   8622     3    149  ...   \n",
      "4      387     5      7   385   349    173     8     39    79    835  ...   \n",
      "5      139     7   1025   118   139    200  2298   2372  1025   2372  ...   \n",
      "6      349    86   1540   179     8    558     7      3   839      7  ...   \n",
      "7       14    28    340     3    17    137    41     20    49    261  ...   \n",
      "8        2  1084     43    58    66     13   255    169   247   6174  ...   \n",
      "9       94    61     90    19   845   4151    34   2858    61     47  ...   \n",
      "10     458     5   1198     2    24    492    43   1960   677    726  ...   \n",
      "11      67     1   1558    10     2   2228     4      6   589  26552  ...   \n",
      "12   39491   364   1005  4144   427    874   731   1120  1031     15  ...   \n",
      "13     215    65      7   351    10      8    69   1946   568     35  ...   \n",
      "14     873     8    183    14   121     31     2     28    11   7187  ...   \n",
      "15      23     7    147    34    56     50     4    177     9    504  ...   \n",
      "\n",
      "    1790  1791  1792  1793  1794  1795  1796  1797  1798  1799  \n",
      "0      0     0     0     0     0     0     0     0     0     0  \n",
      "1      0     0     0     0     0     0     0     0     0     0  \n",
      "2      0     0     0     0     0     0     0     0     0     0  \n",
      "3      0     0     0     0     0     0     0     0     0     0  \n",
      "4      0     0     0     0     0     0     0     0     0     0  \n",
      "5      0     0     0     0     0     0     0     0     0     0  \n",
      "6      0     0     0     0     0     0     0     0     0     0  \n",
      "7      0     0     0     0     0     0     0     0     0     0  \n",
      "8      0     0     0     0     0     0     0     0     0     0  \n",
      "9      0     0     0     0     0     0     0     0     0     0  \n",
      "10     0     0     0     0     0     0     0     0     0     0  \n",
      "11     0     0     0     0     0     0     0     0     0     0  \n",
      "12     0     0     0     0     0     0     0     0     0     0  \n",
      "13     0     0     0     0     0     0     0     0     0     0  \n",
      "14     0     0     0     0     0     0     0     0     0     0  \n",
      "15     0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[16 rows x 1800 columns]\n",
      "    0  1  2  3  4  5\n",
      "0   0  0  0  0  0  0\n",
      "1   0  0  0  0  0  0\n",
      "2   0  0  0  0  0  0\n",
      "3   0  0  0  0  0  0\n",
      "4   0  0  0  0  0  0\n",
      "5   1  1  1  0  1  0\n",
      "6   0  0  0  0  0  0\n",
      "7   0  0  0  0  0  0\n",
      "8   0  0  0  0  0  0\n",
      "9   0  0  0  0  0  0\n",
      "10  0  0  0  0  0  0\n",
      "11  0  0  0  0  0  0\n",
      "12  0  0  0  0  0  0\n",
      "13  0  0  0  0  0  0\n",
      "14  0  0  0  0  0  0\n",
      "15  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "batch_X , batch_y = dataset.as_numpy_iterator().next()\n",
    "X = pd.DataFrame(batch_X)\n",
    "Y = pd.DataFrame(batch_y)\n",
    "print(X.iloc[:])\n",
    "print(Y.iloc[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06b084d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape # 16 samples/batches of len 1800 each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e4336d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1efabbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9974"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fdbd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 per of dataset to train data\n",
    "train = dataset.take(int(len(dataset)*.7)) \n",
    "\n",
    "# Skips first 70 % of dataset and take 20 % from remaining 30%\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "\n",
    "# skips 90% of data and take 10 % remaining for testing use\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85ddd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2679b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[188072,      1,     18, ...,      0,      0,      0],\n",
       "        [ 96950,  19715,    485, ...,      0,      0,      0],\n",
       "        [    82,      2,   2980, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [   171,     46,     55, ...,      0,      0,      0],\n",
       "        [    23,      8,    215, ...,      0,      0,      0],\n",
       "        [  1122,      8,    590, ...,      0,      0,      0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14f991",
   "metadata": {},
   "source": [
    "# 2. Create Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27e08c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sequential api -> Allow us\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Fastest and easiest \n",
    "from tensorflow.keras.layers import LSTM , Dropout , Bidirectional , Dense , Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbcf0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Creating layers\n",
    "model.add(Embedding(MAX_FEATURES+1 , 32)) # 32 length \n",
    "#Adding a Bidirection LSTM layer\n",
    "#32 Different LSTM units/ nueron activation of tanh\n",
    "model.add(Bidirectional(LSTM(32,activation ='tanh')))\n",
    "# Feature Extractor fully connected layers(Dense Layers)\n",
    "model.add(Dense(128 , activation = 'relu'))\n",
    "model.add(Dense(256 , activation = 'relu'))\n",
    "model.add(Dense(128 , activation = 'relu'))\n",
    "#Final layers Connect the output\n",
    "model.add(Dense(  6 , activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab09b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'BinaryCrossentropy' , optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf40a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 1800), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a579f6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6491686 (24.76 MB)\n",
      "Trainable params: 6491686 (24.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29290a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2080/6981 [=======>......................] - ETA: 40:38 - loss: 0.0861"
     ]
    }
   ],
   "source": [
    "history = model.fit(train , epochs = 10 , validation_data = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ff6cf",
   "metadata": {},
   "source": [
    "# 3. Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X , batch_y = test.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e31682",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23162ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025e41d",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e23a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision , Recall , CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce77b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50599fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    #Unpacking the batch\n",
    "    X_true , y_true = batch\n",
    "    \n",
    "    #Making the prediction\n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    #Flatten the prediction\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true , yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision : {pre.result().numpy()}  \\nRecall : {re.result().numpy()} \\nAccuracy : { acc.result().numpy()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = (2 * pre.result().numpy() * re.result().numpy()) / (re.result().numpy() + pre.result().numpy())\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2668000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eb90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1833e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('For fucks sake I will kill you.')\n",
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab86ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf76594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    result = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = \"\"\n",
    "    \n",
    "    for idx,col in enumerate(df.columns[2:]):\n",
    "        text += '{} : {}\\n'.format(col , result[0][idx] > 0.3)\n",
    "        \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ab338",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    Comment = gr.Textbox(label = \"Comment\" , placeholder = \"Enter comment here\")\n",
    "    Results = gr.Textbox(label = \"Results\")\n",
    "    check_toxicity = gr.Button(\"Check Toxicity\")\n",
    "    check_toxicity.click(fn = score_comment,\n",
    "                         inputs = Comment,\n",
    "                         outputs = Results,\n",
    "                         api_name = \"greet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d64c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
